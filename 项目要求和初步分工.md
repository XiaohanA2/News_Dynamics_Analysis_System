# 项目要求

## 1、项目介绍

在本项目中，你需要实现一个新闻实时动态变化分析系统，为PENS数据提供新闻话题实时动态变化分析、各类新闻历史/实时统计，新闻话题推荐等功能。所需要实现的模块大致如下：

**1）新闻数据和点击流数据模拟**：采用PENS中提供的新闻曝光日志（Impression Log），对新闻曝光日志构建模拟日志产生程序，模拟时序的日志产生。

**2）ETL**: 采用Flume框架，采集上一步骤中模拟产生的新闻曝光日志。数据在经过ETL步骤后，需要放入到Kafka的队列中进行流量控制，然后将其存储到你定义的存储系统中。同时获取PENS中的新闻数据。

**3）Storage System**: 该模块应当完成数据的存储（可使用各类关系型或非关系型存储），并为Query Server提供高性能的查询服务。在存储的过程中，应当考虑数据预处理、数据建模、索引等建立的合理性，以提高效率和系统稳定性，达到系统性能指标。

**4）Analysis Server**: 该模块为前端的数据提供智能查询和分析服务，采用Spark Streaming技术，基于AI+BI的Agent的分析方法。应当为前端需要实现的针对新闻动态的检索和分析能力。

**5）UI**: 该模块为前端的数据可视化。需要开发针对新闻动态变化的查询和分析，并对结果进行合理的可视化，以实现对结果集的快速访问。

## 2、数据集

本项目中的数据来源于PENS数据集（https://msnews.github.io/pens.html ，https://www.kaggle.com/datasets/divyapatel4/microsoft-pens-personalized-news-headlines?resource=download ，数据描述参见 msnews 源，数据下载可以使用 Kaggle 源）。数据集中包括新闻、新闻曝光日志等信息。你需要让自己熟悉这个数据集。

PENS的新闻语料库包含了约11万则英文新闻文章，每篇新闻文章都由四部分内容组成：

- 新闻ID
- 新闻标题
- 新闻正文
- 新闻类别标签。

所有训练和测试数据中出现的新闻，都与语料库中文章的新闻ID一一对应。

PENS的训练数据集则包含了匿名用户的新闻曝光日志（Impression Log），其中包括44万名匿名用户的50万次新闻曝光日志，以及每名用户的历史点击信息。具体而言，每一条训练数据都由五部分内容组成：用户ID、曝光时间戳、点击新闻列表、未点击新闻列表、用户历史点击新闻列表。所有列表中出现的新闻按首次曝光时间排序。

为了满足离线评测的需求，研究员们邀请了103名以英语为母语的高校学生（以下简称“标注者”），人工创建PENS的测试数据集。其构造过程分为两个阶段：第一阶段，每位标注者浏览1000条从新闻语料库中随机抽取的新闻标题，并从中选择至少50个自己感兴趣的标题，视为该用户的历史点击行为；第二阶段，每位标注者为另外200篇新闻正文撰写心中的理想标题。这些人工撰写的新闻标题由专业新闻编辑审查质量。低质量的标题会被删除（例如过长、过短或与正文不符），剩余合格的标题作为相应用户的个性化新闻标题的黄金标准。

## 3、评分点

在本项目中你需要实现数据的获取、清洗、存储、查询和可视化的数据流程，其中在每一个模块中你可以发挥自己的能力对系统设计的关键点进行思考和优化，每一个优化点都将使评分提高。

其中详细的评分规则如下：

### 1）基本功能

数据集的**读取、导入**，完成包括但不限于：新闻点击流数据**生成、解析、存储、统计、分析、展示**的基本功能

针对用户的**查询和分析**要求，能够以**可视化的方式进行前端展示**。

### 2）查询和分析

你需要至少实现以下**基本查询**：

2.1、对单个新闻的生命周期的查询，可以展示单个新闻在不同时间段的流行变化

2.2、对某些种类的新闻的变化情况的统计查询，可以展示不同类别的

2.3、对用户兴趣变化的统计查询

2.4、可以按照时间/时间段、新闻主题、新闻标题长度、新闻长度、特定用户、特定多个用户等多种条件和组合进行统计查询

2.7、需要建立查询日志，能够记录所有的SQL查询记录和查询时间，便于对性能指标进行检验和优化

**分析：**

2.5、能够分析什么样的新闻最可能成为爆款新闻

2.6、能够实时按照用户浏览的内容进行新闻推荐

### 3）查询性能要求

3.1、以上任何单个查询需要在1s内完成查询和前端的结果渲染

3.2、前端页面中，一个页面可能包含多个静态或动态查询结果的显示（例如页面中会包含按照每天（2019-6-13到2019-7-3）的不同新闻主题（15种）查询变化情况等），单个页面的也需要在3s内完成查询和前端的结果渲染



# 任务分解

## 项目概述

本项目基于PENS数据集构建实时新闻动态分析系统，包含数据模拟、ETL、存储、分析和用户界面模块。

## 团队分工

**具体实现细节看【项目要求】，所有提出的点需要严格完成。**

### 成员A：新闻数据与点击流模拟

**职责**：

- 开发模拟程序，基于PENS数据集的曝光日志（Impression Log）生成时序新闻曝光日志。

**具体任务**：

- 研究PENS数据集，重点分析曝光日志结构（用户ID、时间戳、点击/未点击新闻列表、历史点击数据）。
- 设计算法模拟真实时序日志，考虑用户行为（点击模式）和新闻流行趋势。
- 实现模拟程序，生成与PENS数据集格式和分布一致的日志。
- 测试模拟数据质量，确保支持下游ETL和分析任务。

**交付内容**：

- 可运行的时序新闻曝光日志模拟程序。
- 模拟算法和数据质量验证文档。

### 成员B：ETL

**职责**：

- 使用Flume框架、Kafka队列和PENS新闻数据进行数据收集、处理和整合。

**具体任务**：

- 配置Flume框架，收集成员A生成的模拟曝光日志。
- 设计ETL流水线，清洗和转换日志数据（例如去重、格式规范化）。
- 将处理后的数据整合到Kafka队列进行流量控制，并为存储系统做准备。
- 获取并处理PENS新闻数据（新闻ID、标题、正文、类别），确保存储兼容性。
- 测试ETL流水线的可靠性和数据完整性。

**交付内容**：

- 配置好的Flume Agent和ETL流水线脚本。
- 准备好存储的处理后日志和新闻数据集。

### 成员C：存储系统服务器

**职责：**

- 构建数据存储系统服务器，支持高性能查询。

**具体任务**：

- 根据查询性能需求选择合适的存储方案（例如MySQL、MongoDB或HBase）。
- 设计数据模型存储处理后的日志和新闻数据，包括预处理（例如规范化）、建模和索引以提高效率。
- 支持高性能查询（例如单次查询<1秒）。

**交付内容**：

- 配置好的存储系统，包含数据模型和索引。

### 成员D：查询、分析服务器

**职责：**

- 构建数据查询及分析服务器，支持实时分析和AI+BI分析。

**具体任务：**

- 学习Spark Streaming技术以处理实时数据。
- 使用AI+BI Agent分析方法开发查询服务器，支持新闻生命周期、类别趋势、用户兴趣变化等查询。
- 实现分析功能，例如预测“爆款”新闻和实时推荐。
- 维护查询日志（SQL查询和时间戳）以监控性能。

**交付内容**：

- 查询服务器和分析服务器（基于Spark Streaming）。
- 查询日志系统，用于性能跟踪。

### 汇总：前端

- **任务**：
  - 设计前端界面，考虑用户需求和交互性。
  - 实现查询和分析功能，包括
    - 单一新闻生命周期趋势。
    - 基于类别的新闻变化。
    - 用户兴趣演变。
    - 多条件查询（例如时间、主题、标题长度）。
    - 爆款新闻预测和实时推荐。
  - 创建可视化（图表、图形）。
  - 优化性能（单查询<1秒，多查询页面<3秒）。
- **输出**：前端界面。



TODO：

1. 爆款新闻、实时推荐（文档）
2. 前端
3. PPT（各自负责）——模板

## 依赖关系

- **成员A → 成员B**：模拟日志输入ETL流水线。
- **成员B → 成员C、成员D**：处理后的数据用于存储和分析。
- **成员C、成员D → 汇总**：存储和分析结果供前端界面使用。

## 指导原则

- **数据集熟悉**：所有成员需深入了解PENS数据集结构（新闻语料库和日志）。
- **接口清晰**：尽早定义模块间数据格式和API。
- **测试**：定期进行代码审查和集成测试，确保系统稳定性。
- **版本控制**：使用Git进行协作开发和代码管理。